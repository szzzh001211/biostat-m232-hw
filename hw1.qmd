---
title: "Biostat M232 Homework 1"
subtitle: Due Feb 7 @ 11:59PM
author: "Ziheng Zhang_606300061"
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
execute:
  eval: true    
---

## Question 1

**Answer:**

In the given problem, we consider a finite population of size $N$ from which a simple random sample of size $n$ is drawn. The sample mean $\bar{y}$ is used to estimate the population mean $\bar{Y}$, and under simple random sampling assumptions, the variance of the sample mean is given by:

$$
\begin{equation}
\operatorname{Var}(\bar{y} - \bar{Y}) = s^2 \left( \frac{1}{n} - \frac{1}{N} \right)
\tag{1}
\end{equation}
$$

where:

- $n$ is the sample size,
- $s^2$ is the sample variance,
- $N$ is the population size.

However, due to random nonresponse, only $n_1$ of the $n$ sampled values are actually observed, resulting in a new sample mean $\bar{y}_1$ and sample variance $s_1^2$. In this case, the variance of the estimator is:

$$
\operatorname{Var}(\bar{y}_1 - \bar{Y}) = s_1^2 \left( \frac{1}{n_1} - \frac{1}{N} \right)
$$

Suppose the missing values are imputed using the mean of the observed data $\bar{y}_1$. The imputed dataset has a total mean still equal to $\bar{y}_1$, but the sample variance becomes:

$$
s_{\text{new}}^2 = s_1^2 \cdot \frac{n_1 - 1}{n - 1}
$$

The resulting variance of the sample mean under this imputation strategy is:

$$
\begin{equation}
\operatorname{Var}(\bar{y} - \bar{Y}) = s_1^2 \left( \frac{1}{n} - \frac{1}{N} \right) \cdot \frac{n_1 - 1}{n - 1}
\tag{2}
\end{equation}
$$
So the ratio of the imputed variance to the complete data variance is:
$$
\frac{\text{Imputed Variance}}{\text{Complete Data Variance}}
= \frac{s_1^2 \left( \frac{1}{n} - \frac{1}{N} \right) \cdot \frac{n_1 - 1}{n - 1}}
{s^2 \left( \frac{1}{n} - \frac{1}{N} \right)}
$$
Assuming $s_1^2 \approx s^2$ (the observed sample is random), the ratio simplifies to:

$$
\frac{n_1 - 1}{n - 1}
$$

When $n_1$ is large, the ratio can be approximated as:

$$
\frac{n_1}{n}
$$
Thus, the resulting interval estimate of $\bar{Y}$ will be too short by a factor approximately equal to
$$
\sqrt{\frac{n_1}{n}}
$$

- If $80\%$ of the data is observed ($n_1 = 0.8n$), the interval width would be reduced by:
$$
\sqrt{\frac{0.8n}{n}} = \sqrt{0.8} \approx 0.894
$$
This implies the interval will be approximately **10.6% narrower** than it would have been with complete data.

- If only 50% of the data is observed ($n_1 = 0.5n$):

  $$
  \sqrt{\frac{0.5n}{n}} = \sqrt{0.5} \approx 0.707
  $$

  The interval will be approximately **29.3% narrower**.

- If just 30% of the data is observed ($n_1 = 0.3n$):

  $$
  \sqrt{\frac{0.3n}{n}} = \sqrt{0.3} \approx 0.548
  $$
  The interval width is **45.2% narrower**.


## Question 2

**Answer:**

First we assume the linear regression model for $Y_1$ on $Y_2$ is:
$$
Y_1 = \beta_0 + \beta_1 Y_2 + \epsilon
$$
where $\epsilon$ is the error term with mean 0 and variance $\sigma^2$. So the conditional mean of $Y_1$ given $Y_2$ is:
$$
E(Y_1|Y_2) = \beta_0 + \beta_1 Y_2
$$

Given that the missingness of $Y_1$ depends only on $Y_2$, the missing data mechanism can be expressed as:
$$
P(Missing|Y_1, Y_2) = P(Missing|Y_2)
$$
This means given $Y_2$, the probability of missingness of $Y_1$ is independent of $Y_1$ but only depends on $Y_2$. So for the complete case$\{Y_1|Y_2 = y_2, observed\}$ has the same distribution as $\{Y_1|Y_2 = y_2\}$ in the full data set. So we have
$$
E(Y_1|Y_2 = y_2, observed) = E(Y_1|Y_2 = y_2)
$$
So we can correctly estimate the true parameter $\beta_1$ and $\beta_0$ using the complete data regression of $Y_1$ on $Y_2$.

The least squares estimates of $\beta_0$ and $\beta_1$ are:
$$
\hat{\beta}_1 = \frac{\sum_{i=1}^n (Y_{1i} - \bar{Y}_1)(Y_{2i} - \bar{Y}_2)}{\sum_{i=1}^n (Y_{2i} - \bar{Y}_2)^2}
$$

$$
\hat{\beta}_0 = \bar{Y}_1 - \hat{\beta}_1 \bar{Y}_2
$$
where $\bar{Y}_1$ and $\bar{Y}_2$ are the sample means of $Y_1$ and $Y_2$ respectively. The expectation of $\hat{\beta}_1$ and $\hat{\beta}_0$ are:
$$
E(\hat{\beta}_1) = \beta_1
$$
$$
E(\hat{\beta}_0) = \beta_0
$$
So the sample regression of $Y_1$ on $Y_2$ based on complete units yields unbiased estimates of the regression parameters.


## Question 3

**Answer:**

The overall mean cholesterol for respondents is calculated using the formula:
$$
\bar{y} = \frac{\sum n_{i,resp} \bar{y}_i}{\sum n_{i,resp}}
$$
Substituting the given values:
$$
\begin{align*}
\bar{y} &= \frac{(22 \times 220) + (27 \times 225) + (16 \times 250) + (5 \times 270)}{22 + 27 + 16 + 5}\\
&= \frac{4840 + 6075 + 4000 + 1350}{70}\\
&= \frac{16265}{70} \approx 232.36
\end{align*}
$$
Thus, the estimated mean cholesterol level for respondents is **232.36**.


The standard error is calculated using:
$$
\operatorname{Var}(\bar{y}) = \frac{1}{\sum n_{i,resp}}\frac{\sum (n_{i,resp}-1) s_i^2}{\sum (n_{i,resp}-1)}
$$
Substituting the values:
$$
\begin{align*}
\sum (n_{i,resp}-1) s_i^2 &= (21 \times 30^2) + (26 \times 35^2) + (15 \times 44^2) + (4 \times 41^2)\\
&= 18900 + 31850 + 29040 + 6724 = 86514\\
\operatorname{Var}(\bar{y}) &= \frac{1}{70} \times \frac{86514}{70 - 4}\\
&= \frac{86514}{66 \times 70} \approx 18.73\\
\text{SE}(\bar{y}) &= \sqrt{18.73} \approx 4.33
\end{align*}
$$
Thus, the standard error is **4.33**.

So the $95\%$ confidence interval for the mean cholesterol level of respondents is:
$$
232.36 \pm 1.96 \times 4.33 = 232.36 \pm 8.48 = [223.87, 240.85]
$$
This interval **cannot** be applied to the entire county population because of **nonresponse bias**, which may introduce systematic differences between respondents and nonrespondents.


## Question 4

**Answer:**

The formula for the weighting class estimate of the mean cholesterol level from Equation (3.6) is:
$$
\bar{y}_{\text{wc}} = n^{-1} \sum_{j=1}^{J} n_j \bar{y}_{jR}
$$
Where:

- \( n_j \) is the sample size for each age group,
- \( \bar{y}_{jR} \) is the respondent mean for each age group,
- \( n \) is the total sample size.

Substituting the given values:
$$
\begin{align*}
\bar{y}_{\text{wc}} &= \frac{1}{100} \left( 25 \times 220 + 35 \times 225 + 28 \times 250 + 12 \times 270 \right)\\
&= \frac{1}{100} (5500 + 7875 + 7000 + 3240)\\
&= \frac{23615}{100} = 236.15
\end{align*}
$$
Thus, the weighted mean cholesterol level for the population is **236.15**.

The formula to the variance from Equation (3.7) is:
$$
\operatorname{Var}(\bar{y}_{\text{wc}}) = \operatorname{Var} \left( \frac{1}{r} \sum_{i=1}^{r} w_i y_i \right) \approx \frac{\sigma^2}{r^2} \left( \sum_{i=1}^{r} w_i^2 \right)
$$
where
- $r$ is the total number of respondents,
- $w_i$ is the weight for unit $i$.

The formula for the weight $w_i$ is:
$$
w_i = r(\hat{\phi}_i)^{-1} \Bigg/ \sum_{k=1}^{r} (\hat{\phi}_k)^{-1}, \quad \text{where } \hat{\phi}_i = \frac{r_j}{n_j} \text{ for units } i \text{ in class } j.
$$
where $\hat{\phi}_i$ is the estimated response probability for unit $i$. $r_j$ is the number of respondents in class $j$ and $n_j$ is the total sample size in class $j$.


So the variance of the weighted mean cholesterol level is:
$$
\begin{align*}
\operatorname{Var}(\bar{y}_{\text{wc}}) &=  \frac{\sigma^2}{r^2} \left( \sum_{i=1}^{r} w_i^2 \right) = \frac{r_1\times (\frac{n_1}{r_1})^2\times s_1^2 + r_2\times (\frac{n_2}{r_2})^2\times s_2^2 + r_3\times (\frac{n_3}{r_3})^2\times s_3^2 + r_4\times (\frac{n_4}{r_4})^2\times s_4^2}{(r_1\times\frac{n_1}{r_1}+ r_2\times\frac{n_2}{r_2}+ r_3\times\frac{n_3}{r_3}+ r_4\times\frac{n_4}{r_4})^2} \\
& = \frac{22\times (\frac{25}{22})^2\times 30^2 + 27\times (\frac{35}{27})^2\times 35^2 + 16\times (\frac{28}{16})^2\times 44^2 + 5\times (\frac{12}{5})^2\times 41^2}{(22\times\frac{25}{22}+27\times\frac{35}{27}+16\times\frac{28}{16}+5\times\frac{12}{5})^2} \\
& = 22.44
\end{align*}
$$
The standard error estimate is:
$$
\text{SE}(\bar{y}_{\text{wc}}) = \sqrt{22.44} \approx 4.74
$$
Thus, the standard error is approximately **4.74**.

The $95\%$ confidence interval for the weighted mean cholesterol level is:
$$
236.15 \pm 1.96 \times 4.74 = 236.15 \pm 9.29 = [226.86, 245.44]
$$
This interval **can** be applied to the entire county population because the weights are used to adjust for nonresponse bias. Compared to the results in Question 3, the weighted mean cholesterol level is higher, and the confidence interval is wider. This is because the weights are used to adjust for nonresponse bias, which may introduce systematic differences between respondents and nonrespondents. The assumptions made about the nonresponse mechanism in this analysis are:

- The nonresponse mechanism is **ignorable**.
- The nonresponse mechanism is **missing at random**.
- Four classes have the **same** probability for a unit selected from a given class to respond.



## Question 5

**Answer:**

The post-stratified mean is calculated as:
$$
\bar{y}_{\text{post}} = \sum_{j=1}^{J} p_j \bar{y}_j
$$
Substituting the values:
$$
\begin{align*}
\bar{y}_{\text{post}} &= (0.20 \times 220) + (0.40 \times 225) + (0.30 \times 250) + (0.10 \times 270)\\
&= 44 + 90 + 75 + 27\\
&= 236
\end{align*}
$$
Thus, the post-stratified estimate of the mean cholesterol level is **236**.

The standard error for post-stratified estimation is computed using:
$$
\text{SE}(\bar{y}_{\text{post}}) = \sqrt{\sum_{j=1}^{J} p_j^2 \cdot \frac{s_j^2}{n_{j,resp}}}
$$
Substituting the values:
$$
\begin{align*}
\text{SE}(\bar{y}_{\text{post}}) &= \sqrt{(0.2^2 \times \frac{30^2}{22}) + (0.4^2 \times \frac{35^2}{27}) + (0.3^2 \times \frac{44^2}{16}) + (0.1^2 \times \frac{41^2}{5})}\\
&= \sqrt{1.63 + 7.26 + 10.89 + 3.36}\\
&= \sqrt{23.14} \approx 4.81
\end{align*}
$$
Thus, the standard error is **4.81**.

The $95\%$ confidence interval for the post-stratified mean cholesterol level is:
$$
236 \pm 1.96 \times 4.81 = 236 \pm 9.42 = [226.57, 245.43]
$$


## Question 6

**Answer:**

From the Equation (3.18):
$$
r^*_{jk} = \frac{s^{(jk)}_{jk}}{\sqrt{s^{(j)}_{jj} s^{(k)}_{kk}}}
$$
Let's create a data set and use the above formula to estimate the correlation.
```{r}
library(tidyverse)
data <- tibble(
  Subject = 1:4,
  Y1 = c(1, 2, NA, 4),
  Y2 = c(NA, 2, 3, 4)
)
available_cases <- data |>
  filter(!is.na(Y1) & !is.na(Y2))

s_12 <- cov(available_cases$Y1, available_cases$Y2)

s_11 <- var(data$Y1, na.rm = TRUE)
s_22 <- var(data$Y2, na.rm = TRUE)

r_star <- s_12 / sqrt(s_11 * s_22)
r_star
```
The estimated correlation coefficient is **1.31**, which lies outside the range of -1 to 1.


## Question 7

### (a)

**Answer:**

The estimated variance of $Y_1$ from the filled-in data underestimates the magnitude of the variance by a factor 
$$
\frac{n^{j}-1}{n-1}
$$
where $n^{j}$ is the number of complete cases for the variable $Y_j$. So the the percentage bias in estimates of the variance is:
$$
1- \frac{35-1}{45-1} \times 100\%  = 22.7\%
$$


### (b)

**Answer:**

The estimated covariance from the filled-in data underestimates the magnitude of the covariance by a factor 
$$
\frac{n^{jk}-1}{n-1}
$$
where $n^{jk}$ is the number of complete cases for the pair of variables $Y_j$ and $Y_k$. So the the percentage bias in estimates of the covariance is:
$$
1- \frac{20-1}{45-1} \times 100\%  = 56.8\%
$$


### (c)

**Answer:**

The estimated slope of the regression of $Y_2$ on $Y_1$ ($\frac{\sigma_{12}}{\sigma_{11}}$) is 
$$
\hat{\beta} = \frac{\hat{\sigma}_{12}}{\hat{\sigma}_{11}} = \frac{\frac{19}{44}\sigma_{12}}{\frac{34}{44}\sigma_{11}} = \frac{19}{34}\beta
$$
So the bias in the estimate of the slope is:
$$
1- \frac{19}{34} \times 100\% = 44.1\%
$$



## Question 8

**Answer:**

**The Last Observation Carried Forward (LOCF)** method is used in longitudinal studies with dropouts. When a subject drops out, their last recorded value is carried forward to impute missing values:
$$
\hat{y}_{it} = y_{i,k-1}, \quad t = k, \dots, K.
$$
LOCF performs poorly in clinical trials for progressive diseases like Alzheimer's and frototemporal dementia(FTD), where patients who experience faster cognitive decline are more likely to drop out. By carrying forward their last recorded cognitive score, LOCF artificially stabilizes disease progression, leading to an underestimation of decline and biasing treatment effect estimates.


## Question 9

**Answer:**

The CC estimator is:
$$
\hat{\Delta}_{CC} = \bar{X}_1^{(m)} - \bar{X}_2^{(m)}
$$
<!-- where: -->
<!-- - \( \bar{X}_1^{(m)} \) is the mean of \( X_1 \) for the \( m \) cases where \( X_2 \) is observed. -->
<!-- - \( \bar{X}_2^{(m)} \) is the mean of these \( m \) individuals' \( X_2 \) values. -->
Since both means are computed from the same $m$ cases, the variance is:
$$
\begin{align*}
\text{Var}(\hat{\Delta}_{CC}) &= \text{Var}(\bar{X}_1^{(m)} - \bar{X}_2^{(m)})\\
&= \text{Var}(\bar{X}_1^{(m)}) + \text{Var}(\bar{X}_2^{(m)}) - 2\text{Cov}(\bar{X}_1^{(m)}, \bar{X}_2^{(m)})\\
&= \frac{\sigma^2}{m} + \frac{\sigma^2}{m} - 2\frac{\rho \sigma^2}{m}\\
&= \frac{2\sigma^2(1-\rho)}{m}
\end{align*}
$$
The AC estimator is:
$$
\hat{\Delta}_{AC} = \bar{X}_1^{(n)} - \bar{X}_2^{(m)}
$$
<!-- where: -->
<!-- - \( \bar{X}_1^{(n)} \) is the sample mean of all \( n \) observations on \( X_1 \). -->
<!-- - \( \bar{X}_2^{(m)} \) is the sample mean of the \( m \) observed \( X_2 \) values. -->

Since $X_1$ is based on $n$ cases and $X_2$ on $m$ cases, the variance is:
$$
\begin{align*}
\text{Var}(\hat{\Delta}_{AC}) &= \text{Var}(\frac{1}{n}\Sigma_{i=1}^{m}X_{1i} - \frac{1}{m}\Sigma_{i=1}^{m}X_{2i} + \frac{1}{n}\Sigma_{i=m+1}^{n}X_{1i})\\
&= \text{Var}(\frac{1}{n}\Sigma_{i=1}^{m}X_{1i} - \frac{1}{m}\Sigma_{i=1}^{m}X_{2i}) + \text{Var}(\frac{1}{n}\Sigma_{i=m+1}^{n}X_{1i})\\
&= \text{Var}(\frac{1}{n}\Sigma_{i=1}^{m}X_{1i}) + \text{Var}(\frac{1}{m}\Sigma_{i=1}^{m}X_{2i}) - 2\text{Cov}(\frac{1}{n}\Sigma_{i=1}^{m}X_{1i}, \frac{1}{m}\Sigma_{i=1}^{m}X_{2i}) + \text{Var}(\frac{1}{n}\Sigma_{i=m+1}^{n}X_{1i})\\
&= \frac{m\sigma^2}{n^2} + \frac{\sigma^2}{m} - 2\frac{\rho \sigma^2}{n} + \frac{(n-m)\sigma^2}{n^2}\\
&= \frac{\sigma^2}{n} + \frac{\sigma^2}{m} - 2\frac{\rho \sigma^2}{n}
\end{align*}
$$

For the variance of AC to be less than that of CC, we need:
$$
\begin{align*}
\text{Var}(\hat{\Delta}_{AC}) - \text{Var}(\hat{\Delta}_{CC}) &= \frac{\sigma^2}{n} + \frac{\sigma^2}{m} - 2\frac{\rho \sigma^2}{n} - \frac{2\sigma^2(1-\rho)}{m} < 0\\
&= \frac{(1-2\rho)\sigma^2}{n} - \frac{(1-2\rho)\sigma^2}{m} < 0\\
&= \frac{(1-2\rho)(m-n)\sigma^2}{nm} < 0\\
\Rightarrow (1-2\rho) &> 0, \text{ since } (m-n) < 0\\
\Rightarrow \rho &< 0.5
\end{align*}
$$
So when the correlation between $X_1$ and $X_2$ is less than 0.5, the variance of the AC estimator is less than that of the CC estimator.


## Question 10

**Answer:**

The overall sample mean $\bar{y}^*$ is the weighted mean of the respondents and nonrespondents:
$$
\begin{align*}
\bar{y}^* &= \frac{1}{n} \sum_{i=1}^{n} y_i\\
&=\frac{n_1 \bar{y}_1 + n_0 \bar{y}_0}{n}.
\tag{1}
\end{align*}
$$

The sample variance is defined as:
$$
s^{*2} = \frac{1}{n-1} \sum_{i=1}^{n} (y_i - \bar{y}^*)^2.
$$
Since we have two groups, we split the sum:
$$
s^{*2} = \frac{1}{n-1} \left[ \sum_{i=1}^{n_1} (y_i - \bar{y}^*)^2 + \sum_{i=1}^{n_0} (y_i - \bar{y}^*)^2 \right].
$$
We first decompose the sum for the respondents:
$$
\begin{align*}
\sum_{i=1}^{n_1} (y_i - \bar{y}^*)^2 &= \sum_{i=1}^{n_1} (y_i - \bar{y}_1 + \bar{y}_1 - \bar{y}^*)^2\\
&= \sum_{i=1}^{n_1} (y_i - \bar{y}_1)^2 + 2 \sum_{i=1}^{n_1} (y_i - \bar{y}_1)(\bar{y}_1 - \bar{y}^*) + \sum_{i=1}^{n_1} (\bar{y}_1 - \bar{y}^*)^2\\
&= \sum_{i=1}^{n_1} (y_i - \bar{y}_1)^2 + n_1 (\bar{y}_1 - \bar{y}^*)^2\\
&= (n_1 - 1) s_1^2 + n_1 (\bar{y}_1 - \bar{y}^*)^2
\end{align*}
$$
Similarly, for the nonrespondents:
$$
\begin{align*}
\sum_{i=1}^{n_0} (y_i - \bar{y}^*)^2 &= \sum_{i=1}^{n_0} (y_i - \bar{y}_0 + \bar{y}_0 - \bar{y}^*)^2\\
&= \sum_{i=1}^{n_0} (y_i - \bar{y}_0)^2 + 2 \sum_{i=1}^{n_0} (y_i - \bar{y}_0)(\bar{y}_0 - \bar{y}^*) + \sum_{i=1}^{n_0} (\bar{y}_0 - \bar{y}^*)^2\\
&= \sum_{i=1}^{n_0} (y_i - \bar{y}_0)^2 + n_0 (\bar{y}_0 - \bar{y}^*)^2\\
&= (n_0 - 1) s_0^2 + n_0 (\bar{y}_0 - \bar{y}^*)^2
\end{align*}
$$

By using Equation (1), we can have
$$
\begin{align*}
\bar{y}_1 - \bar{y}^* &= \bar{y}_1 - \frac{n_1 \bar{y}_1 + n_0 \bar{y}_0}{n}\\
&= \frac{n_0}{n} (\bar{y}_1 - \bar{y}_0)\\
\bar{y}_0 - \bar{y}^* &= \frac{n_1}{n} (\bar{y}_0 - \bar{y}_1)
\end{align*}
$$
So 
$$
\begin{align*}
(\bar{y}_1 - \bar{y}^*)^2 &= \frac{n_0^2}{n^2} (\bar{y}_1 - \bar{y}_0)^2\\
(\bar{y}_0 - \bar{y}^*)^2 &= \frac{n_1^2}{n^2} (\bar{y}_1 - \bar{y}_0)^2
\end{align*}
$$
So we can rewrite the sum of squares as:
$$
\begin{align*}
\sum_{i=1}^{n_1} (y_i - \bar{y}^*)^2 &= (n_1 - 1) s_1^2 + \frac{n_1 n_0^2}{n^2} (\bar{y}_1 - \bar{y}_0)^2\\
\sum_{i=1}^{n_0} (y_i - \bar{y}^*)^2 &= (n_0 - 1) s_0^2 + \frac{n_0 n_1^2}{n^2} (\bar{y}_1 - \bar{y}_0)^2
\end{align*}
$$
Substituting into the variance equation, we can get
$$
s^{*2} = \frac{(n_1 - 1) s_1^2 + (n_0 - 1) s_0^2 + \frac{n_1 n_0}{n} (\bar{y}_1 - \bar{y}_0)^2}{n-1}.
$$



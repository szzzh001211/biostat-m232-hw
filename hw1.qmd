---
title: "Biostat M232 Homework 1"
subtitle: Due Feb 7 @ 11:59PM
author: "Ziheng Zhang_606300061"
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
execute:
  eval: true    
---

## Question 1

**Answer:**

In the given problem, we consider a finite population of size $N$ from which a simple random sample of size $n$ is drawn. The sample mean $\bar{y}$ is used to estimate the population mean $\bar{Y}$, and under simple random sampling assumptions, the variance of the sample mean is given by:

$$
\begin{equation}
\operatorname{Var}(\bar{y} - \bar{Y}) = s^2 \left( \frac{1}{n} - \frac{1}{N} \right)
\tag{1}
\end{equation}
$$

where:

- $n$ is the sample size,
- $s^2$ is the sample variance,
- $N$ is the population size.

However, due to random nonresponse, only $n_1$ of the $n$ sampled values are actually observed, resulting in a new sample mean $\bar{y}_1$ and sample variance $s_1^2$. In this case, the variance of the estimator with complete data is:

$$
\operatorname{Var}(\bar{y}_1 - \bar{Y}) = s_1^2 \left( \frac{1}{n_1} - \frac{1}{N} \right)
$$

Suppose the missing values are imputed using the mean of the observed data $\bar{y}_1$. The imputed dataset has a total mean still equal to $\bar{y}_1$, but the sample variance becomes:

$$
s_{\text{new}}^2 = s_1^2 \cdot \frac{n_1 - 1}{n - 1}
$$

The resulting variance of the sample mean under this imputation strategy is:

$$
\begin{equation}
\operatorname{Var}(\bar{y} - \bar{Y}) = s_1^2 \left( \frac{1}{n} - \frac{1}{N} \right) \cdot \frac{n_1 - 1}{n - 1}
\tag{2}
\end{equation}
$$
So the ratio of the imputed variance to the complete data variance is:
$$
\frac{\text{Imputed Variance}}{\text{Complete Data Variance}}
= \frac{s_1^2 \left( \frac{1}{n} - \frac{1}{N} \right) \cdot \frac{n_1 - 1}{n - 1}}
{s^2 \left( \frac{1}{n_1} - \frac{1}{N} \right)}
$$
Assuming $s_1^2 \approx s^2$ (the observed sample is random), the ratio simplifies to:

$$
\sqrt{\frac{\left( \frac{1}{n} - \frac{1}{N} \right) \cdot \frac{n_1 - 1}{n - 1}}
{\left( \frac{1}{n_1} - \frac{1}{N} \right)}} \approx \frac{n_1}{n}
$$
when $n_1$ and $\frac{N}{n_1}$ are large.

Thus, the resulting interval estimate of $\bar{Y}$ will be too short by a factor approximately equal to
$$
\frac{n_1}{n}
$$

- If $80\%$ of the data is observed ($n_1 = 0.8n$), the interval width would be reduced by:
$$
\frac{0.8n}{n} = 0.8
$$



## Question 2

**Answer:**

First we assume the linear regression model for $Y_1$ on $Y_2$ is:
$$
Y_1 = \beta_0 + \beta_1 Y_2 + \epsilon
$$
where $\epsilon$ is the error term with mean 0 and variance $\sigma^2$. So the conditional mean of $Y_1$ given $Y_2$ is:
$$
E(Y_1|Y_2) = \beta_0 + \beta_1 Y_2
$$

Given that the missingness of $Y_1$ depends only on $Y_2$, the missing data mechanism can be expressed as:
$$
P(Missing|Y_1, Y_2) = P(Missing|Y_2)
$$
This means given $Y_2$, the probability of missingness of $Y_1$ is independent of $Y_1$ but only depends on $Y_2$. So for the complete case$\{Y_1|Y_2 = y_2, observed\}$ has the same distribution as $\{Y_1|Y_2 = y_2\}$ in the full data set. So we have
$$
E(Y_1|Y_2 = y_2, observed) = E(Y_1|Y_2 = y_2)
$$
So we can correctly estimate the true parameter $\beta_1$ and $\beta_0$ using the complete data regression of $Y_1$ on $Y_2$.

The least squares estimates of $\beta_0$ and $\beta_1$ are:
$$
\hat{\beta}_1 = \frac{\sum_{i=1}^n (Y_{1i} - \bar{Y}_1)(Y_{2i} - \bar{Y}_2)}{\sum_{i=1}^n (Y_{2i} - \bar{Y}_2)^2}
$$

$$
\hat{\beta}_0 = \bar{Y}_1 - \hat{\beta}_1 \bar{Y}_2
$$
where $\bar{Y}_1$ and $\bar{Y}_2$ are the sample means of $Y_1$ and $Y_2$ respectively. The expectation of $\hat{\beta}_1$ and $\hat{\beta}_0$ are:
$$
E(\hat{\beta}_1) = \beta_1
$$
$$
E(\hat{\beta}_0) = \beta_0
$$
So the sample regression of $Y_1$ on $Y_2$ based on complete units yields unbiased estimates of the regression parameters.


## Question 3

**Answer:**

The overall mean cholesterol for respondents is calculated using the formula:
$$
\bar{y} = \frac{\sum n_{i,resp} \bar{y}_i}{\sum n_{i,resp}}
$$
Substituting the given values:
$$
\begin{align*}
\bar{y} &= \frac{(22 \times 220) + (27 \times 225) + (16 \times 250) + (5 \times 270)}{22 + 27 + 16 + 5}\\
&= \frac{4840 + 6075 + 4000 + 1350}{70}\\
&= \frac{16265}{70} \approx 232.36
\end{align*}
$$
Thus, the estimated mean cholesterol level for respondents is **232.36**.

The sample variance is calculated using:
$$
\begin{align*}
s^2 &= \frac{\sum_{i=1}^{I} \sum_{j=1}^{n_{i,resp}} (y_{ij} - \bar{y})^2}{N-1} = \frac{\sum_{i=1}^{I} \sum_{j=1}^{J} (y_{ij} - \bar{y}_i)^2 + \sum_{i=1}^{I} n_{i,resp} (\bar{y}_i - \bar{y})^2}{N-1}\\
&= \frac{1}{N-1}\left[\sum_{i=1}^{4} (n_{i,resp}-1) s_i^2 + n_{i,resp} (\bar{y}_i - \bar{y})^2 \right]\\
&= \frac{103400}{70-1}\\
&= 1498.551
\end{align*}
$$
So the estimated variance of mean cholesterol level for respondents is $$\operatorname{Var}(\bar{y}) = \frac{s^2}{70} = \frac{1498.551}{70} \approx 21.41$$

Thus, the standard error is **4.63**.

So the $95\%$ confidence interval for the mean cholesterol level of respondents is:
$$
232.36 \pm 1.96 \times 4.63 = 232.36 \pm 9.07 = (223.29, 241.43)
$$
This interval **cannot** be applied to the entire county population because of **nonresponse bias**, which may introduce systematic differences between respondents and nonrespondents.


## Question 4

**Answer:**

The formula for the weighting class estimate of the mean cholesterol level from Equation (3.6) is:
$$
\bar{y}_{\text{wc}} = \frac{1}{n} \sum_{j=1}^{J} n_j \bar{y}_{jR}
$$
Where:

- $n_j$ is the sample size for each age group,
- $\bar{y}_{jR}$ is the respondent mean for each age group,
- $n$ is the total sample size.

Substituting the given values:
$$
\begin{align*}
\bar{y}_{\text{wc}} &= \frac{1}{100} \left( 25 \times 220 + 35 \times 225 + 28 \times 250 + 12 \times 270 \right)\\
&= \frac{1}{100} (5500 + 7875 + 7000 + 3240)\\
&= \frac{23615}{100} = 236.15
\end{align*}
$$
Thus, the weighted mean cholesterol level for the population is **236.15**.

The formula to the estimated mean squared error from Equation (3.8) is:
$$
\text{mse}(\hat{\bar{y}}_{\text{wc}}) =
\sum_{j=1}^{J} \left( \frac{n_j}{n} \right)^2 
\left( 1 - \frac{r_j n}{n_j N} \right) \frac{s^2_{jR}}{r_j} 
+ \frac{N - n}{(N - 1) n^2} 
\sum_{j=1}^{J} n_j (\bar{y}_{jR} - \bar{y}_{\text{wc}})^2
$$
where $s^2_{jR}$ is the variance of sampled and responding units in class $j$. Here we assume 
$$
\frac{n}{N} \approx  0, \quad \text{and} \quad \frac{N - n}{N - 1} \approx 1
$$
Substituting the given values:
$$
\begin{align*}
\text{mse}(\hat{\bar{y}}_{\text{wc}}) &= \left( \frac{25}{100} \right)^2  \frac{30^2}{22} +
\left( \frac{35}{100} \right)^2  \frac{35^2}{27} + \left( \frac{28}{100} \right)^2  \frac{44^2}{16} + \left( \frac{12}{100} \right)^2  \frac{41^2}{5} \\
&+ \frac{1}{100^2} \left[ 25 \times (220 - 236.15)^2 + 35 \times (225 - 236.15)^2 + 28 \times (250 - 236.15)^2 + 12 \times (270 - 236.15)^2 \right]\\
&=25.44
\end{align*}
$$

The $95\%$ confidence interval for the weighted mean cholesterol level is:
$$
236.15 \pm 1.96 \times \sqrt{25.44} = 236.15 \pm 9.89 = (226.26, 246.04)
$$
This interval **can** be applied to the entire county population because the weights are used to adjust for nonresponse bias. Compared to the results in Question 3, the weighted mean cholesterol level is higher, and the confidence interval is wider. This is because the weights are used to adjust for nonresponse bias, which may introduce systematic differences between respondents and nonrespondents. 

It has Quasirandomization assumption (Respondents in weighting class $j$ are a random sample of the sampled units, i.e. the data are MCAR within adjustment class j).



## Question 5

**Answer:**

The post-stratified mean is calculated as:
$$
\bar{y}_{\text{post}} = \sum_{j=1}^{J} p_j \bar{y}_j
$$
Substituting the values:
$$
\begin{align*}
\bar{y}_{\text{post}} &= (0.20 \times 220) + (0.40 \times 225) + (0.30 \times 250) + (0.10 \times 270)\\
&= 44 + 90 + 75 + 27\\
&= 236
\end{align*}
$$
Thus, the post-stratified estimate of the mean cholesterol level is **236**.

The standard error for post-stratified estimation is computed using:
$$
\text{SE}(\bar{y}_{\text{post}}) = \sqrt{\sum_{j=1}^{J} p_j^2 \cdot \frac{s_j^2}{n_{j,resp}}}
$$
Substituting the values:
$$
\begin{align*}
\text{SE}(\bar{y}_{\text{post}}) &= \sqrt{(0.2^2 \times \frac{30^2}{22}) + (0.4^2 \times \frac{35^2}{27}) + (0.3^2 \times \frac{44^2}{16}) + (0.1^2 \times \frac{41^2}{5})}\\
&= \sqrt{1.63 + 7.26 + 10.89 + 3.36}\\
&= \sqrt{23.14} \approx 4.81
\end{align*}
$$
Thus, the standard error is **4.81**.

The $95\%$ confidence interval for the post-stratified mean cholesterol level is:
$$
236 \pm 1.96 \times 4.81 = 236 \pm 9.42 = [226.57, 245.43]
$$


## Question 6

**Answer:**

From the Equation (3.18):
$$
r^*_{jk} = \frac{s^{(jk)}_{jk}}{\sqrt{s^{(j)}_{jj} s^{(k)}_{kk}}}
$$
Let's create a data set and use the above formula to estimate the correlation.
```{r}
library(tidyverse)
data <- tibble(
  Subject = 1:4,
  Y1 = c(1, 2, NA, 4),
  Y2 = c(NA, 2, 3, 4)
)
available_cases <- data |>
  filter(!is.na(Y1) & !is.na(Y2))

s_12 <- cov(available_cases$Y1, available_cases$Y2)

s_11 <- var(data$Y1, na.rm = TRUE)
s_22 <- var(data$Y2, na.rm = TRUE)

r_star <- s_12 / sqrt(s_11 * s_22)
r_star
```
The estimated correlation coefficient is **1.31**, which lies outside the range of -1 to 1.


## Question 7

### (a)

**Answer:**

The estimated variance of $Y_1$ from the filled-in data underestimates the magnitude of the variance by a factor 
$$
\frac{n^{j}-1}{n-1}
$$
where $n^{j}$ is the number of complete cases for the variable $Y_j$. So the the percentage bias in estimates of the variance is:
$$
1- \frac{35-1}{45-1} \times 100\%  = 22.7\%
$$


### (b)

**Answer:**

The estimated covariance from the filled-in data underestimates the magnitude of the covariance by a factor 
$$
\frac{n^{jk}-1}{n-1}
$$
where $n^{jk}$ is the number of complete cases for the pair of variables $Y_j$ and $Y_k$. So the the percentage bias in estimates of the covariance is:
$$
1- \frac{20-1}{45-1} \times 100\%  = 56.8\%
$$


### (c)

**Answer:**

The estimated slope of the regression of $Y_2$ on $Y_1$ ($\frac{\sigma_{12}}{\sigma_{11}}$) is 
$$
\hat{\beta} = \frac{\hat{\sigma}_{12}}{\hat{\sigma}_{11}} = \frac{\frac{19}{44}\sigma_{12}}{\frac{34}{44}\sigma_{11}} = \frac{19}{34}\beta
$$
So the bias in the estimate of the slope is:
$$
1- \frac{19}{34} \times 100\% = 44.1\%
$$



## Question 8

**Answer:**

**The Last Observation Carried Forward (LOCF)** method is used in longitudinal studies with dropouts. When a subject drops out, their last recorded value is carried forward to impute missing values:
$$
\hat{y}_{it} = y_{i,k-1}, \quad t = k, \dots, K.
$$
LOCF performs poorly in clinical trials for progressive diseases like Alzheimer's and frototemporal dementia(FTD), where patients who experience faster cognitive decline are more likely to drop out. By carrying forward their last recorded cognitive score, LOCF artificially stabilizes disease progression, leading to an underestimation of decline and biasing treatment effect estimates.


## Question 9

**Answer:**

The CC estimator is:
$$
\hat{\Delta}_{CC} = \bar{X}_1^{(m)} - \bar{X}_2^{(m)}
$$
<!-- where: -->
<!-- - \( \bar{X}_1^{(m)} \) is the mean of \( X_1 \) for the \( m \) cases where \( X_2 \) is observed. -->
<!-- - \( \bar{X}_2^{(m)} \) is the mean of these \( m \) individuals' \( X_2 \) values. -->
Since both means are computed from the same $m$ cases, the variance is:
$$
\begin{align*}
\text{Var}(\hat{\Delta}_{CC}) &= \text{Var}(\bar{X}_1^{(m)} - \bar{X}_2^{(m)})\\
&= \text{Var}(\bar{X}_1^{(m)}) + \text{Var}(\bar{X}_2^{(m)}) - 2\text{Cov}(\bar{X}_1^{(m)}, \bar{X}_2^{(m)})\\
&= \frac{\sigma^2}{m} + \frac{\sigma^2}{m} - 2\frac{\rho \sigma^2}{m}\\
&= \frac{2\sigma^2(1-\rho)}{m}
\end{align*}
$$
The AC estimator is:
$$
\hat{\Delta}_{AC} = \bar{X}_1^{(n)} - \bar{X}_2^{(m)}
$$
<!-- where: -->
<!-- - \( \bar{X}_1^{(n)} \) is the sample mean of all \( n \) observations on \( X_1 \). -->
<!-- - \( \bar{X}_2^{(m)} \) is the sample mean of the \( m \) observed \( X_2 \) values. -->

Since $X_1$ is based on $n$ cases and $X_2$ on $m$ cases, the variance is:
$$
\begin{align*}
\text{Var}(\hat{\Delta}_{AC}) &= \text{Var}(\frac{1}{n}\Sigma_{i=1}^{m}X_{1i} - \frac{1}{m}\Sigma_{i=1}^{m}X_{2i} + \frac{1}{n}\Sigma_{i=m+1}^{n}X_{1i})\\
&= \text{Var}(\frac{1}{n}\Sigma_{i=1}^{m}X_{1i} - \frac{1}{m}\Sigma_{i=1}^{m}X_{2i}) + \text{Var}(\frac{1}{n}\Sigma_{i=m+1}^{n}X_{1i})\\
&= \text{Var}(\frac{1}{n}\Sigma_{i=1}^{m}X_{1i}) + \text{Var}(\frac{1}{m}\Sigma_{i=1}^{m}X_{2i}) - 2\text{Cov}(\frac{1}{n}\Sigma_{i=1}^{m}X_{1i}, \frac{1}{m}\Sigma_{i=1}^{m}X_{2i}) + \text{Var}(\frac{1}{n}\Sigma_{i=m+1}^{n}X_{1i})\\
&= \frac{m\sigma^2}{n^2} + \frac{\sigma^2}{m} - 2\frac{\rho \sigma^2}{n} + \frac{(n-m)\sigma^2}{n^2}\\
&= \frac{\sigma^2}{n} + \frac{\sigma^2}{m} - 2\frac{\rho \sigma^2}{n}
\end{align*}
$$

For the variance of AC to be less than that of CC, we need:
$$
\begin{align*}
\text{Var}(\hat{\Delta}_{AC}) - \text{Var}(\hat{\Delta}_{CC}) &= \frac{\sigma^2}{n} + \frac{\sigma^2}{m} - 2\frac{\rho \sigma^2}{n} - \frac{2\sigma^2(1-\rho)}{m} < 0\\
&= \frac{(1-2\rho)\sigma^2}{n} - \frac{(1-2\rho)\sigma^2}{m} < 0\\
&= \frac{(1-2\rho)(m-n)\sigma^2}{nm} < 0\\
\Rightarrow (1-2\rho) &> 0, \text{ since } (m-n) < 0\\
\Rightarrow \rho &< 0.5
\end{align*}
$$
So when the correlation between $X_1$ and $X_2$ is less than 0.5, the variance of the AC estimator is less than that of the CC estimator.


## Question 10

**Answer:**

The overall sample mean $\bar{y}^*$ is the weighted mean of the respondents and nonrespondents:
$$
\begin{align*}
\bar{y}^* &= \frac{1}{n} \sum_{i=1}^{n} y_i\\
&=\frac{n_1 \bar{y}_1 + n_0 \bar{y}_0}{n}.
\tag{1}
\end{align*}
$$

The sample variance is defined as:
$$
s^{*2} = \frac{1}{n-1} \sum_{i=1}^{n} (y_i - \bar{y}^*)^2.
$$
Since we have two groups, we split the sum:
$$
s^{*2} = \frac{1}{n-1} \left[ \sum_{i=1}^{n_1} (y_i - \bar{y}^*)^2 + \sum_{i=1}^{n_0} (y_i - \bar{y}^*)^2 \right].
$$
We first decompose the sum for the respondents:
$$
\begin{align*}
\sum_{i=1}^{n_1} (y_i - \bar{y}^*)^2 &= \sum_{i=1}^{n_1} (y_i - \bar{y}_1 + \bar{y}_1 - \bar{y}^*)^2\\
&= \sum_{i=1}^{n_1} (y_i - \bar{y}_1)^2 + 2 \sum_{i=1}^{n_1} (y_i - \bar{y}_1)(\bar{y}_1 - \bar{y}^*) + \sum_{i=1}^{n_1} (\bar{y}_1 - \bar{y}^*)^2\\
&= \sum_{i=1}^{n_1} (y_i - \bar{y}_1)^2 + n_1 (\bar{y}_1 - \bar{y}^*)^2\\
&= (n_1 - 1) s_1^2 + n_1 (\bar{y}_1 - \bar{y}^*)^2
\end{align*}
$$
Similarly, for the nonrespondents:
$$
\begin{align*}
\sum_{i=1}^{n_0} (y_i - \bar{y}^*)^2 &= \sum_{i=1}^{n_0} (y_i - \bar{y}_0 + \bar{y}_0 - \bar{y}^*)^2\\
&= \sum_{i=1}^{n_0} (y_i - \bar{y}_0)^2 + 2 \sum_{i=1}^{n_0} (y_i - \bar{y}_0)(\bar{y}_0 - \bar{y}^*) + \sum_{i=1}^{n_0} (\bar{y}_0 - \bar{y}^*)^2\\
&= \sum_{i=1}^{n_0} (y_i - \bar{y}_0)^2 + n_0 (\bar{y}_0 - \bar{y}^*)^2\\
&= (n_0 - 1) s_0^2 + n_0 (\bar{y}_0 - \bar{y}^*)^2
\end{align*}
$$

By using Equation (1), we can have
$$
\begin{align*}
\bar{y}_1 - \bar{y}^* &= \bar{y}_1 - \frac{n_1 \bar{y}_1 + n_0 \bar{y}_0}{n}\\
&= \frac{n_0}{n} (\bar{y}_1 - \bar{y}_0)\\
\bar{y}_0 - \bar{y}^* &= \frac{n_1}{n} (\bar{y}_0 - \bar{y}_1)
\end{align*}
$$
So 
$$
\begin{align*}
(\bar{y}_1 - \bar{y}^*)^2 &= \frac{n_0^2}{n^2} (\bar{y}_1 - \bar{y}_0)^2\\
(\bar{y}_0 - \bar{y}^*)^2 &= \frac{n_1^2}{n^2} (\bar{y}_1 - \bar{y}_0)^2
\end{align*}
$$
So we can rewrite the sum of squares as:
$$
\begin{align*}
\sum_{i=1}^{n_1} (y_i - \bar{y}^*)^2 &= (n_1 - 1) s_1^2 + \frac{n_1 n_0^2}{n^2} (\bar{y}_1 - \bar{y}_0)^2\\
\sum_{i=1}^{n_0} (y_i - \bar{y}^*)^2 &= (n_0 - 1) s_0^2 + \frac{n_0 n_1^2}{n^2} (\bar{y}_1 - \bar{y}_0)^2
\end{align*}
$$
Substituting into the variance equation, we can get
$$
s^{*2} = \frac{(n_1 - 1) s_1^2 + (n_0 - 1) s_0^2 + \frac{n_1 n_0}{n} (\bar{y}_1 - \bar{y}_0)^2}{n-1}.
$$


